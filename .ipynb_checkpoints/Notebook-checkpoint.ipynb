{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Respondent Classification\n",
    "\n",
    "## Author: Sumit Kutty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 300)\n",
    "\n",
    "from warnings import filterwarnings as w\n",
    "w('ignore')\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "\n",
    "#ML\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"SpendData.csv\")\n",
    "data = dataset.copy()\n",
    "test = pd.read_csv(\"TestData.csv\")\n",
    "target = data['pov6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        0\n",
       "month             0\n",
       "var8           4009\n",
       "var6          16480\n",
       "a.1               0\n",
       "              ...  \n",
       "c.281             0\n",
       "c.282             0\n",
       "c.283             0\n",
       "f.284          4418\n",
       "t.158         18379\n",
       "Length: 301, dtype: int64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle null values and reconciling the features of train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(data, test):\n",
    "    #TRAIN SET\n",
    "    for i in data.columns:\n",
    "        if i not in test.columns:\n",
    "            data.drop(i, axis = 1, inplace = True)\n",
    "    for i in test.columns:\n",
    "        if i not in data.columns:\n",
    "            test.drop(i, axis = 1, inplace =True)\n",
    "        \n",
    "        \n",
    "    # remove other redundant features\n",
    "    data.drop(['Unnamed: 0','pov6'], axis = 1, inplace = True)\n",
    "    test.drop(['Unnamed: 0','pov6'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "        \n",
    "    red_cols = []\n",
    "    train_nulls = []\n",
    "    for i in data.columns:\n",
    "        if data[i].isnull().sum() > 800:\n",
    "            red_cols.append(i)\n",
    "        elif data[i].isnull().sum() < 800 and data[i].isnull().sum() > 0 and i != 'pov6':\n",
    "            train_nulls.append(i)\n",
    "        \n",
    "        \n",
    "\n",
    "    # remove features with more than 800 null values in train set from both train and test set    \n",
    "    data.drop(red_cols, axis = 1, inplace = True)\n",
    "    test.drop(red_cols, axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #TEST SET\n",
    "    test_nulls = []\n",
    "    red_cols2 = []\n",
    "    for i in test.columns:\n",
    "        if test[i].isnull().sum() > 800:\n",
    "            red_cols2.append(i)\n",
    "        elif test[i].isnull().sum() < 800 and test[i].isnull().sum() > 0:\n",
    "            test_nulls.append(i)\n",
    "   \n",
    "    \n",
    "\n",
    "    # remove features with more than 800 null values in test set from both train and test set    \n",
    "    data.drop(red_cols2, axis = 1, inplace = True)\n",
    "    test.drop(red_cols2, axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in train_nulls: #train_nulls: missing values in train set\n",
    "        if i not in test_nulls and i in test.columns:\n",
    "            continue\n",
    "        elif i not in test_nulls and i not in test.columns:\n",
    "            train_nulls.remove(i)\n",
    "        \n",
    "    for i in test_nulls:\n",
    "        if i not in train_nulls and i in data.columns:\n",
    "            continue\n",
    "        elif i not in train_nulls and i not in data.columns:\n",
    "            test_nulls.remove(i)\n",
    "   \n",
    "\n",
    "    data.drop(['respondent.id','year'], axis = 1, inplace = True)\n",
    "    test.drop(['respondent.id','year'], axis = 1, inplace = True)\n",
    "        \n",
    "        \n",
    "    return train_nulls, test_nulls, data, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The above function removes features with more than 800 null values. Retains the features with less than 800 null values. returns train nulls and test nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nulls, test_nulls, data, test = equalize(data,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n",
      "239\n"
     ]
    }
   ],
   "source": [
    "print(len(data.columns))\n",
    "print(len(test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in train_nulls:\n",
    "    sns.distplot(data[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The features are roughly normally distributed. Either mean or median can be used to replace the null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing means: \n",
    "The means of train data features are used to impute features in both train data and test data to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy = 'mean')\n",
    "imputer2 = SimpleImputer(strategy = 'most_frequent')\n",
    "if len(train_nulls) != 0:\n",
    "    for i in train_nulls:\n",
    "        if i not in cat_feats: \n",
    "            data[i] = imputer.fit_transform(np.array(data[i]).reshape(-1,1))\n",
    "        else:\n",
    "            data[i] = imputer2.fit_transform(np.array(data[i]).reshape(-1,1))\n",
    "\n",
    "if len(test_nulls) != 0:        \n",
    "    for i in test_nulls:\n",
    "        if i not in cat_feats:\n",
    "            imputer.fit(np.array(data[i]).reshape(-1,1))\n",
    "            test[i] = imputer.transform(np.array(test[i]).reshape(-1,1))\n",
    "        else:\n",
    "            imputer2.fit(np.array(data[i]).reshape(-1,1))\n",
    "            test[i] = imputer2.transform(np.array(test[i]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* At this stage, all columns of train and test are the same with no null values.\n",
    "* There doesn't seem to be the need to any feature engineering apart from one hot encoding the categorical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The standard deviation of the columns are pretty far away from each other. Standardization might be essential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the categorical variables:\n",
    "cat_feats  =['month', 'var9']\n",
    "\n",
    "# One hot encode 'month' and 'var9'\n",
    "data_dum = pd.get_dummies(data[cat_feats].astype('str'))\n",
    "test_dum = pd.get_dummies(test[cat_feats].astype('str'))\n",
    "\n",
    "\n",
    "data_scaled = data.drop(cat_feats, axis = 1)\n",
    "test_scaled = test.drop(cat_feats, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the variables\n",
    "data_scaled = pd.DataFrame(scaler.fit_transform(data_scaled), columns = data_scaled.columns)\n",
    "test_scaled = pd.DataFrame(scaler.transform(test_scaled), columns = test_scaled.columns)\n",
    "\n",
    "# Concatenate the scaled numerical variables and the one-hot encoded categorical variables\n",
    "data_scaled = pd.concat([data_scaled,data_dum], axis = 1)\n",
    "test_scaled = pd.concat([test_scaled,test_dum], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over sampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "smote  = SMOTENC(categorical_features = [0])\n",
    "\n",
    "data_us, target_us = smote.fit_sample(data_scaled, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as pca\n",
    "\n",
    "n_pc = 30\n",
    "pca = pca(n_components = n_pc)\n",
    "\n",
    "\n",
    "colnames = ['PC' + str(i) for i in range(1, n_pc+1)]\n",
    "data_pc = pd.DataFrame(pca.fit_transform(data_us), columns = colnames)\n",
    "test_pc = pd.DataFrame(pca.transform(test_scaled), columns = colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(data, target, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'saga')\n",
    "rf = RandomForestClassifier(n_estimators = 500)\n",
    "dt = DecisionTreeClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "print(\"ACCURACY:\")\n",
    "print(\"Logistic Regression: \", np.mean(cross_val_score(lr, data_pc, target_us, cv = kfold)))\n",
    "print(\"Random Forest: \", np.mean(cross_val_score(rf, data_pc, target_us, cv = kfold)))\n",
    "print(\"Decision Tree: \", np.mean(cross_val_score(dt, data_pc, target_us, cv = kfold)))\n",
    "print(\"KNN: \", np.mean(cross_val_score(knn, data_pc, target_us, cv = kfold)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf_grid = RandomForestClassifier()\n",
    "params = {'n_estimators':[100,200,300,400,500,600], 'criterion': ['gini','entropy'], 'max_depth':[20,30,40,50,60,80, 100,None], \n",
    "          'max_features': ['auto', 'sqrt', 'log2'], 'min_impurity_decrease':[0.0001,0.001,0.01,0.1], 'min_impurity_split':[0.0001,0.001,0.01,0.1]}\n",
    "grid_model = RandomizedSearchCV(rf_grid, cv=5, param_distributions = params, n_iter = 20)\n",
    "grid_model.fit(data, target)\n",
    "\n",
    " \n",
    "print(\"Grid search score is: \", grid_model.best_score_)\n",
    "print(\"Grid search estimator: \", grid_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The tuned model is tested for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model.fit(xtrain,ytrain)\n",
    "ypred2 = grid_model.predict(xtest)\n",
    "\n",
    "\n",
    "labels = list(target.value_counts().index)\n",
    "labels = [str(i) for i in labels]\n",
    "print(\"Accuracy: \", accuracy_score(ytest,ypred2))\n",
    "print()\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(ytest, ypred2, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
